{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Impact of Job Training Programs on Earnings using the Lalonde Dataset.\n",
    "This dataset is a common benchmark for causal analysis. Original analysis of the study was done by Robert LaLonde and published in his 1986 Evaluating the Econometric Evaluations of Training Programs with Experimental Data paper.\n",
    "We seek to estimate the causal impact of a job training program on the post-treatment earnings of individuals in the treated group compared to those in the control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        614 non-null    object \n",
      " 1   treat     614 non-null    int64  \n",
      " 2   age       614 non-null    int64  \n",
      " 3   educ      614 non-null    int64  \n",
      " 4   black     614 non-null    int64  \n",
      " 5   hispan    614 non-null    int64  \n",
      " 6   married   614 non-null    int64  \n",
      " 7   nodegree  614 non-null    int64  \n",
      " 8   re74      614 non-null    float64\n",
      " 9   re75      614 non-null    float64\n",
      " 10  re78      614 non-null    float64\n",
      "dtypes: float64(3), int64(7), object(1)\n",
      "memory usage: 52.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/prachijhamb/Downloads/lalonde_data.csv')\n",
    "data.info()\n",
    "# A data frame with 614 observations (185 treated, 429 control). There are 10 variables measured for each individual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#Define the treatment and covariate columns\n",
    "treatment_col = 'treat'\n",
    "covariate_cols = ['age', 'educ','black', 'hispan', 'married', 'nodegree', 're74', 're75']\n",
    "# Scale the covariates\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data[covariate_cols])\n",
    "# Fit the logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)  # also increasing iterations\n",
    "logistic_model.fit(X_scaled, data[treatment_col])\n",
    "# Add the propensity score to the data frame\n",
    "data['propensity_score'] = logistic_model.predict_proba(X_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_treated_and_control(df, treatment_col, propensity_score_col):\n",
    "    treated_df = df[df[treatment_col] == 1]\n",
    "    control_df = df[df[treatment_col] == 0]\n",
    "\n",
    "    # Nearest-neighbor matching based on propensity scores\n",
    "    nn_matcher = NearestNeighbors(n_neighbors=1)\n",
    "    nn_matcher.fit(control_df[propensity_score_col].values.reshape(-1, 1))\n",
    "\n",
    "    distances, indices = nn_matcher.kneighbors(treated_df[propensity_score_col].values.reshape(-1, 1))\n",
    "    matched_control_df = control_df.iloc[indices.flatten()]\n",
    "\n",
    "    return treated_df, matched_control_df\n",
    "\n",
    "treated_df, matched_control_df = match_treated_and_control(data, treatment_col, 'propensity_score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Average Treatment Effect (ATE): 1110.12\n"
     ]
    }
   ],
   "source": [
    "def estimate_ate(treated_df, control_df, outcome_col):\n",
    "    treated_outcome_mean = treated_df[outcome_col].mean()\n",
    "    control_outcome_mean = control_df[outcome_col].mean()\n",
    "    return treated_outcome_mean - control_outcome_mean\n",
    "\n",
    "# Estimate the average treatment effect (ATE)\n",
    "ate = estimate_ate(treated_df, matched_control_df, 're78')\n",
    "print(f\"Estimated Average Treatment Effect (ATE): {ate:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 - Inverse Probability of Treatment Weighting \n",
    "Used to estimate the Average Treatment Effect (ATE) by weighting individuals in the treatment and control groups based on the inverse of their propensity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(df, treatment_col, propensity_score_col):\n",
    "    treatment = df[treatment_col]\n",
    "    propensity_score = df[propensity_score_col]\n",
    "    weights = np.where(treatment == 1, 1 / propensity_score, 1 / (1 - propensity_score))\n",
    "    return weights\n",
    "\n",
    "# Calculate IPTWs and add them to the dataset\n",
    "data['iptw'] = calculate_weights(data, treatment_col, 'propensity_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Average Treatment Effect (ATE) using IPTW: 232.42\n"
     ]
    }
   ],
   "source": [
    "def weighted_outcome_analysis(df, treatment_col, outcome_col, weights_col):\n",
    "    weighted_outcome_sum = np.sum(df[treatment_col] * df[outcome_col] * df[weights_col])\n",
    "    weighted_treatment_sum = np.sum(df[treatment_col] * df[weights_col])\n",
    "    treated_outcome_mean = weighted_outcome_sum / weighted_treatment_sum\n",
    "\n",
    "    weighted_outcome_sum = np.sum((1 - df[treatment_col]) * df[outcome_col] * df[weights_col])\n",
    "    weighted_treatment_sum = np.sum((1 - df[treatment_col]) * df[weights_col])\n",
    "    control_outcome_mean = weighted_outcome_sum / weighted_treatment_sum\n",
    "\n",
    "    return treated_outcome_mean - control_outcome_mean\n",
    "\n",
    "# Estimate the average treatment effect (ATE) using IPTW\n",
    "ate_iptw = weighted_outcome_analysis(data, treatment_col, 're78', 'iptw')\n",
    "print(f\"Estimated Average Treatment Effect (ATE) using IPTW: {ate_iptw:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3 - Doubly Robust (DR)- estimate the Average Treatment Effect (ATE) by \n",
    "# combining the strengths of both Propensity Score Matching and Inverse Probability of Treatment Weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_outcome_regression(df, treatment_col, covariate_cols, outcome_col):\n",
    "    treated_df = df[df[treatment_col] == 1]\n",
    "    control_df = df[df[treatment_col] == 0]\n",
    "\n",
    "    treated_model = LinearRegression().fit(treated_df[covariate_cols], treated_df[outcome_col])\n",
    "    control_model = LinearRegression().fit(control_df[covariate_cols], control_df[outcome_col])\n",
    "\n",
    "    return treated_model, control_model\n",
    "\n",
    "treated_outcome_model, control_outcome_model = fit_outcome_regression(data, treatment_col, covariate_cols, 're78')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Average Treatment Effect (ATE) using Doubly Robust Estimation: 1580.86\n"
     ]
    }
   ],
   "source": [
    "def doubly_robust_estimation(df, treatment_col, covariate_cols, outcome_col, propensity_score_col, treated_model, control_model):\n",
    "    treated_df = df[df[treatment_col] == 1]\n",
    "    control_df = df[df[treatment_col] == 0]\n",
    "\n",
    "    treated_term = treated_df[outcome_col] - treated_model.predict(treated_df[covariate_cols]) + treated_df[propensity_score_col] * treated_df[outcome_col] / treated_df[propensity_score_col]\n",
    "    control_term = control_model.predict(control_df[covariate_cols]) - control_df[propensity_score_col] * control_df[outcome_col] / (1 - control_df[propensity_score_col])\n",
    "\n",
    "    treated_outcome_mean = np.mean(treated_term)\n",
    "    control_outcome_mean = np.mean(control_term)\n",
    "\n",
    "    return treated_outcome_mean - control_outcome_mean\n",
    "\n",
    "ate_dr = doubly_robust_estimation(data, treatment_col, covariate_cols, 're78', 'propensity_score', treated_outcome_model, control_outcome_model)\n",
    "print(f\"Estimated Average Treatment Effect (ATE) using Doubly Robust Estimation: {ate_dr:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
