{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second pratice code for the application of Double Machine Learning (DML) to estimate the effect of 401(k) elligiblity on retirement savings. \n",
    "The 401K data considered here is from the Survey of Income and Program Participation (SIPP) from the year 1991. We use the data taken from the application in Chernozhukov et al. (2018). This time we play around with different models and compare the results. \n",
    "401(k) plans are pension accounts sponsored by employers. A major challenge in assessing the impact of participating in 401(k) plans on accumulated savings arises from saver heterogeneity and the non-random nature of enrollment decisions. Individuals differ significantly in their preferences for saving, and it is reasonable to assume that those with stronger, unobserved preferences for saving are more inclined to participate in tax-advantaged retirement plans such as 401(k)s. Consequently, these individuals likely have higher accumulated assets regardless of participation. Failure to account for this saver heterogeneity and the endogenous nature of participation decisions leads to upward-biased estimates, overstating the actual savings effects attributable to 401(k) participation.\n",
    "\n",
    "To address this bias, it can be argued that eligibility for enrolling in a 401(k) plan can be considered exogenous once certain observable factors, especially income, are controlled for. This argument rests on the premise that when 401(k) plans were initially introduced, employment decisions were generally driven by income and other job characteristics, rather than by the availability of a 401(k). Thus, after conditioning on income and similar observables, eligibility for a 401(k) is less likely to be correlated with unobserved preferences for saving.- source:https://docs.doubleml.org/dev/examples/py_double_ml_pension.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use net financial assets (net_tfa) as the outcome variable. The treatment variable is 401(k) elligibility (e401). The covariates are age, income, education, marital status and other worker characteristics such as family size, dual-earner status, defined-benefit pension, IRA participation, and home ownership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "# Load the dataset\n",
    "data = pd.read_stata('/Users/prachijhamb/Downloads/sipp1991.dta')\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(\"Outcome (net_tfa) and treatment (p401) summary:\")\n",
    "print(data[['net_tfa','p401']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable e401 indicates eligibility and p401 indicates participation in 401(k) plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a bar plot of the eligibility for 401(k) plans. The variable e401 has two values: 1 if the respondent is eligible for a 401(k) plan and 0 otherwise.\n",
    "# Define colors explicitly\n",
    "colors = ['#1f77b4', '#ff7f0e']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Set matplotlib attribute to plot the graph inline\n",
    "%matplotlib inline\n",
    "# Plotting\n",
    "data['e401'].value_counts().plot(kind='bar', color=colors)\n",
    "plt.title('Eligibility for 401(k)', fontsize=14)\n",
    "plt.xlabel('e401', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density plots below show the comparison between these two groups. We notice that individuals eligible for a 401(k) (e401 = 1) generally have higher net total financial assets compared to individuals who are not eligible (e401 = 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Set up FacetGrid to create separate plots based on 'e401'\n",
    "g = sns.FacetGrid(data, col='e401', hue='e401', palette='Set2', height=5, aspect=1.2, sharey=True)\n",
    "\n",
    "# Add density plots within each facet\n",
    "g.map(sns.kdeplot, 'net_tfa', fill=True, common_norm=False, alpha=0.5)\n",
    "\n",
    "# Set x-axis limits to match your ggplot specification\n",
    "g.set(xlim=(-20000, 150000))\n",
    "\n",
    "# Add titles and axis labels\n",
    "g.set_axis_labels('net_tfa', 'Density')\n",
    "g.set_titles('e401 = {col_name}')\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Estimate average potential outcomes\n",
    "We compute the simple difference in means or the unconditional average predictive effect (APE) of 401(k) eligibility on accumulated assets. This measure would reflect the average treatment effect if eligibility for a 401(k) plan were randomly assigned across all individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data where e401 == 1 and e401 == 0\n",
    "e1 = data[data['e401'] == 1]\n",
    "e0 = data[data['e401'] == 0]\n",
    "\n",
    "# Calculate the simple difference in means for net_tfa\n",
    "mean_diff_e = round(np.mean(e1['net_tfa']) - np.mean(e0['net_tfa']), 0)\n",
    "print(mean_diff_e)\n",
    "\n",
    "# Filter data based on p401\n",
    "p1 = data[data['p401'] == 1]\n",
    "p0 = data[data['p401'] == 0]\n",
    "\n",
    "# Compute and round the difference in means\n",
    "mean_diff_p = round(np.mean(p1['net_tfa']) - np.mean(p0['net_tfa']), 0)\n",
    "print(mean_diff_p )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unconditional APE of e401 is about 19559: individuals eligible for a 401(k) have about $19559 more in net total financial assets compared to those who are not eligible.\n",
    "Among the 3682 individuals that are eligible,  2594 decided to participate in the program. The unconditional APE of p401 is about  27372: individuals who participate in a 401(k) have about $27372 more in net total financial assets compared to those who do not participate.\n",
    "But, these estimates are biased since they do not account for the non-random nature of 401(k) participation decisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and outcome variables\n",
    "control = ['age', 'inc', 'educ', 'fsize', 'marr', 'twoearn', 'db', 'pira', 'hown']\n",
    "outcome = 'net_tfa'\n",
    "treatment = 'e401'\n",
    "\n",
    "# Initialize basic DoubleMLData object\n",
    "data_dml_base = dml.DoubleMLData(data, \n",
    "                                 y_col= outcome,\n",
    "                                 d_cols= treatment,\n",
    "                                 x_cols=control)\n",
    "\n",
    "print(data_dml_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "## Step 4: Construct Polynomial Features for Flexible Model\n",
    "# Start with indicator features\n",
    "features = data[['marr', 'twoearn', 'db', 'pira', 'hown']].copy()\n",
    "\n",
    "# Dictionary specifying polynomial degrees for selected variables\n",
    "poly_dict = {'age': 2,\n",
    "             'inc': 2,\n",
    "             'educ': 2,\n",
    "             'fsize': 2}\n",
    "\n",
    "# Create polynomial features\n",
    "for key, degree in poly_dict.items():\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    data_poly = poly.fit_transform(data[[key]])\n",
    "    poly_feature_names = poly.get_feature_names_out([key])\n",
    "    data_poly_df = pd.DataFrame(data_poly, columns=poly_feature_names, index=data.index)\n",
    "\n",
    "    # Concatenate polynomial features\n",
    "    features = pd.concat([features, data_poly_df], axis=1)\n",
    "\n",
    "# Combine with outcome and treatment\n",
    "model_data = pd.concat([data[['net_tfa', 'e401']], features], axis=1)\n",
    "model_data\n",
    "# Initialize the flexible DoubleMLData object\n",
    "data_dml_flex = dml.DoubleMLData(model_data,\n",
    "                                 y_col='net_tfa',\n",
    "                                 d_cols='e401')\n",
    "\n",
    "print(data_dml_flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "## Step 3: Define Lasso Learners for DoubleML\n",
    "# Lasso for outcome (regression)\n",
    "lasso_g = LassoCV(cv=5, random_state=123)\n",
    "\n",
    "# Lasso for treatment (classification)\n",
    "lasso_m = LogisticRegressionCV(cv=5, penalty='l1', solver='saga', max_iter=10000, random_state=123)\n",
    "\n",
    "\n",
    "## Step 4: Initialize and Fit the PLR Model\n",
    "# Assuming 'data_ml' is already created as per previous step\n",
    "dml_plr = dml.DoubleMLPLR(data_ml,\n",
    "                          ml_g=lasso_g,\n",
    "                          ml_m=lasso_m,\n",
    "                          n_folds=3)\n",
    "\n",
    "# Fit the model and store predictions\n",
    "dml_plr.fit(store_predictions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model in Strategy 1 gives us the ATE estimate of about 5K, while Strateg 2 (DML-PLM) gives that ATE estimate of about 8K. Thus, OLS-LM understates the ATE effect by roughly 30% in relative terms.\n",
    "\n",
    "Since DML-PLM in Strategy 2 is strictly more general than the LM in Strategy 1, we realize that the basic linear model is a pretty bad model in this example.\n",
    "\n",
    "In summary, we've used DML-PLM to validate the simple linear model and ended up rejecting it as not very sensible. Here we can just go ahead and use DML-PLM model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
